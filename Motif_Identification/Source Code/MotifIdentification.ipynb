{"cells":[{"cell_type":"code","execution_count":null,"id":"c54d0d5d-edbf-4de5-85ff-89811d705fb1","metadata":{"id":"c54d0d5d-edbf-4de5-85ff-89811d705fb1","outputId":"1eedcd07-2fc7-4ec8-c926-bfd531cdefc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 2.2445, Validation Accuracy: 0.1818\n","Epoch [2/10], Loss: 2.1120, Validation Accuracy: 0.3091\n","Epoch [3/10], Loss: 1.6062, Validation Accuracy: 0.6545\n","Epoch [4/10], Loss: 0.9448, Validation Accuracy: 0.8909\n","Epoch [5/10], Loss: 0.5295, Validation Accuracy: 0.8909\n","Epoch [6/10], Loss: 0.3449, Validation Accuracy: 0.9273\n","Epoch [7/10], Loss: 0.2303, Validation Accuracy: 0.8545\n","Epoch [8/10], Loss: 0.1365, Validation Accuracy: 0.9455\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, datasets\n","import matplotlib.pyplot as plt\n","\n","# Define directories for train and validation data\n","train_dir = '#Change to data path'\n","validation_dir = '#Change to data path'\n","\n","# Define transforms for data augmentation and normalization\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Define batch size\n","batch_size = 32\n","\n","# Load images from directories\n","train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataset = datasets.ImageFolder(validation_dir, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","class CNNAttention(nn.Module):\n","    def __init__(self):\n","        super(CNNAttention, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.conv5 = nn.Conv2d(256, 512, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(512 * 7 * 7, 512)\n","        self.fc2 = nn.Linear(512, 11)\n","        self.attention = nn.Sequential(\n","            nn.Conv2d(512, 1, kernel_size=1),  # Apply attention across spatial dimensions\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.pool(nn.functional.relu(self.conv1(x)))\n","        x = self.pool(nn.functional.relu(self.conv2(x)))\n","        x = self.pool(nn.functional.relu(self.conv3(x)))\n","        x = self.pool(nn.functional.relu(self.conv4(x)))\n","        x = self.pool(nn.functional.relu(self.conv5(x)))\n","        att_weights = self.attention(x)\n","        x = x * att_weights\n","        x = x.view(-1, 512 * 7 * 7)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Initialize the model\n","model = CNNAttention()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","num_epochs = 25\n","train_acc_history = []\n","val_acc_history = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_dataset)\n","    train_accuracy = correct_train / total_train\n","    train_acc_history.append(train_accuracy)\n","\n","    # Validation\n","    model.eval()\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","    val_accuracy = correct_val / total_val\n","    val_acc_history.append(val_accuracy)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","# Plotting\n","plt.plot(range(1, num_epochs+1), train_acc_history, label='Training Accuracy')\n","plt.plot(range(1, num_epochs+1), val_acc_history, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"14e89bee-a970-4f43-be47-d9933b7e2a60","metadata":{"id":"14e89bee-a970-4f43-be47-d9933b7e2a60"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}